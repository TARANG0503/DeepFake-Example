{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DFL DeepFakes Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "IYtWMzOvLQ3s",
        "BDg_jiQ9adQe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cKdTCuv4tXh"
      },
      "source": [
        "# Welcome to DFL-Colab!\n",
        "\n",
        "This is an adapted version of the DFL for Google Colab.\n",
        "\n",
        "\n",
        "# Overview\n",
        "*   Extractor works in full functionality.\n",
        "*   Training can work without preview.\n",
        "*   Merger works in full functionality.\n",
        "*   You can import/export workspace with your Google Drive.\n",
        "*   Import/export and another manipulations with workspace you can do in \"Manage workspace\" block\n",
        "*   Google Colab machine active for 12 hours. DFL-Colab makes a backup of your workspace in training mode.\n",
        "*   Google does not like long-term heavy calculations. Therefore, for training more than two sessions in a row, use two Google accounts. It is recommended to split your training over 2 accounts, but you can use one Google Drive account to store your workspace.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYtWMzOvLQ3s"
      },
      "source": [
        "## Prevent random disconnects\n",
        "\n",
        "This cell runs JS code to automatic reconnect to runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtClEMAMLVHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "688ac95a-7d0a-4db8-f520-bdf84eb5185b"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDg_jiQ9adQe"
      },
      "source": [
        "## Check GPU\n",
        "\n",
        "*   Google Colab can provide you with one of Tesla graphics cards: K80, T4, P4 or P100\n",
        "*   Here you can check the model of GPU before using DeepFaceLab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJe71S6gbzt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaebb09b-7b9b-4db0-f9a6-8d3dca581d56"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVn21kt40Gw"
      },
      "source": [
        "## Install or update DeepFaceLab\n",
        "\n",
        "* Install or update DeepFAceLab directly from Github\n",
        "* Requirements install is automatically\n",
        "* Automatically sets timer to prevent random disconnects\n",
        "* \"Download FFHQ\" option means to download high quality FFHQ dataset instead of CelebA. FFHQ takes up more memory, so it will take longer to download than CelebA. It is recommended to enable this option if you are doing pretrain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG-f2WqT4fLK",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0bf84b7-8bdc-4214-f97b-e19f04c8d7f4"
      },
      "source": [
        "#@title Install or update DeepFaceLab from Github\n",
        "\n",
        "Mode = \"install\" #@param [\"install\", \"update\"]\n",
        "Download_FFHQ = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "pretrain_link = \"https://github.com/chervonij/DFL-Colab/releases/download/\"\n",
        "pretrain_link = pretrain_link+\"pretrain_FFHQ/pretrain_FFHQ.zip\" if Download_FFHQ else pretrain_link+\"pretrain-CelebA/pretrain_CelebA.zip\"\n",
        "\n",
        "from pathlib import Path\n",
        "if (Mode == \"install\"):\n",
        "  !git clone https://github.com/iperov/DeepFaceLab.git\n",
        "\n",
        "  # fix linux warning\n",
        "  # /usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"rt\")\n",
        "  data = fin.read()\n",
        "  data = data.replace('if cache:', 'if False:')\n",
        "  fin.close()\n",
        "\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"wt\")\n",
        "  fin.write(data)\n",
        "  fin.close()\n",
        "else:\n",
        "  %cd /content/DeepFaceLab\n",
        "  !git pull\n",
        "\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install -r /content/DeepFaceLab/requirements-colab.txt\n",
        "!pip install --upgrade scikit-image\n",
        "!apt-get install cuda-10-0\n",
        "\n",
        "if not Path(\"/content/pretrain\").exists():\n",
        "  print(\"Downloading Pretrain faceset ... \")\n",
        "  !wget -q --no-check-certificate -r $pretrain_link -O /content/pretrain_faceset.zip\n",
        "  !mkdir /content/pretrain\n",
        "  !unzip -q /content/pretrain_faceset.zip -d /content/pretrain/\n",
        "  !rm /content/pretrain_faceset.zip\n",
        "\n",
        "if not Path(\"/content/pretrain_Q96\").exists():\n",
        "  print(\"Downloading Q96 pretrained model ...\")\n",
        "  !wget -q --no-check-certificate -r 'https://github.com/chervonij/DFL-Colab/releases/download/Q96_model_pretrained/Q96_model_pretrained.zip' -O /content/pretrain_Q96.zip\n",
        "  !mkdir /content/pretrain_Q96\n",
        "  !unzip -q /content/pretrain_Q96.zip -d /content/pretrain_Q96/\n",
        "  !rm /content/pretrain_Q96.zip\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  !mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model  \n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"\\nDone!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepFaceLab'...\n",
            "remote: Enumerating objects: 7422, done.\u001b[K\n",
            "remote: Counting objects: 100% (174/174), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 7422 (delta 91), reused 126 (delta 76), pack-reused 7248\u001b[K\n",
            "Receiving objects: 100% (7422/7422), 815.47 MiB | 21.51 MiB/s, done.\n",
            "Resolving deltas: 100% (4769/4769), done.\n",
            "Checking out files: 100% (207/207), done.\n",
            "Uninstalling tensorflow-2.5.0:\n",
            "  Successfully uninstalled tensorflow-2.5.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 1)) (4.41.1)\n",
            "Collecting numpy==1.19.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/b3/07864c89acb2a86df6f2e8c9bf091ec5916da58dd3ce3a633a51a02c115e/numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 312kB/s \n",
            "\u001b[?25hCollecting h5py==2.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/fd/2ca5c4f4ed33ac4178f9c4d551e3946ab480866e3cd67a65a67a4bb35367/h5py-2.9.0-cp37-cp37m-manylinux1_x86_64.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 34.9MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.1.0.25\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/52/61b9619a7a95a8d809515f68f1441224a07ce1873fd3af5e662851014a55/opencv_python-4.1.0.25-cp37-cp37m-manylinux1_x86_64.whl (26.6MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6MB 48.4MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.1.17\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/10/330cbc8e63d072d40413f4d470444a6a1e8c8c6a80b2a4ac302d1252ca1b/ffmpeg_python-0.1.17-py3-none-any.whl\n",
            "Collecting scikit-image==0.14.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/66/a7f7649e5abf9cf1a908134fe6b52f8c5bb4e4059e47dd497bd173a951c6/scikit_image-0.14.2-cp37-cp37m-manylinux1_x86_64.whl (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 100kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 7)) (1.4.1)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting tensorflow-gpu==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/3c/f70e7545e6e41e8be0228526af1f3a0d3bd434d8e30ca8e08a673b0ffe6c/tensorflow_gpu-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.9.0->-r /content/DeepFaceLab/requirements-colab.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.1.17->-r /content/DeepFaceLab/requirements-colab.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.5.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (1.3.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: dask[array]>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.12.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.1.2)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (2.5.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.34.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.12.1)\n",
            "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/ed/5853ec0ae380cba4588eab1524e18ece1583b65f7ae0e97321f5ff9dfd60/tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.36.2)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.12.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=1.8->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (4.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.7/dist-packages (from dask[array]>=1.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (0.11.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.30.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.3.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (4.0.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.1->-r /content/DeepFaceLab/requirements-colab.txt (line 9)) (3.7.4.3)\n",
            "\u001b[31mERROR: kapre 0.3.5 requires tensorflow>=2.0.0, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.3.1 has requirement h5py<2.11.0,>=2.10.0, but you'll have h5py 2.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 2.3.1 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, h5py, opencv-python, ffmpeg-python, scikit-image, colorama, tensorflow-estimator, gast, tensorflow-gpu\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Found existing installation: scikit-image 0.16.2\n",
            "    Uninstalling scikit-image-0.16.2:\n",
            "      Successfully uninstalled scikit-image-0.16.2\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "Successfully installed colorama-0.4.4 ffmpeg-python-0.1.17 gast-0.3.3 h5py-2.9.0 numpy-1.19.3 opencv-python-4.1.0.25 scikit-image-0.14.2 tensorflow-estimator-2.3.0 tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-image\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/01/3a830f3df578ea3ed94ee7fd9f91e85c3dec2431d8548ab1c91869e51450/scikit_image-0.18.1-cp37-cp37m-manylinux1_x86_64.whl (29.2MB)\n",
            "\u001b[K     |████████████████████████████████| 29.2MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.4.8)\n",
            "Requirement already satisfied, skipping upgrade: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5.1)\n",
            "Requirement already satisfied, skipping upgrade: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.19.3)\n",
            "Requirement already satisfied, skipping upgrade: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scikit-image\n",
            "  Found existing installation: scikit-image 0.14.2\n",
            "    Uninstalling scikit-image-0.14.2:\n",
            "      Successfully uninstalled scikit-image-0.14.2\n",
            "Successfully installed scikit-image-0.18.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda-10-0 is already the newest version (10.0.130-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Downloading Pretrain faceset ... \n",
            "Downloading Q96 pretrained model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwOlJG4MdLC"
      },
      "source": [
        "## Manage workspace\n",
        "\n",
        "\n",
        "\n",
        "*   You can import/export workspace or individual data, like model files with Google Drive\n",
        "*   Also, you can use HFS (HTTP Fileserver) for directly import/export you workspace from your computer\n",
        "*   You can clear all workspace or delete part of it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2OvQHyjc7tc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4w_sUzgOQmL",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1668092-4677-4d3a-9d25-16e0a25ca481"
      },
      "source": [
        "#@title Import from Drive\n",
        "\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"models\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  unzip_cmd=\" -q \"+Archive_name\n",
        "  \n",
        "  %cd $path\n",
        "  copy_cmd = \"/content/drive/My\\ Drive/\"+Archive_name+\" \"+path\n",
        "  !cp $copy_cmd\n",
        "  !unzip $unzip_cmd    \n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "  \n",
        "print(\"Done!\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y3WfuwoNXqC",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a45fea-f358-4a15-f747-e4ac5e209819"
      },
      "source": [
        "#@title Export to Drive { form-width: \"30%\" }\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"merged\", \"merged_mask\", \"models\", \"result video\", \"result_mask video\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  zip_cmd=\"-r -q \"+Archive_name+\" \"\n",
        "  \n",
        "  %cd $path\n",
        "  zip_cmd+=mode\n",
        "  !zip $zip_cmd\n",
        "  copy_cmd = \" \"+Archive_name+\"  /content/drive/My\\ Drive/\"\n",
        "  !cp $copy_cmd\n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"merged\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged\")\n",
        "elif Mode == \"merged_mask\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged_mask\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "elif Mode == \"result video\":\n",
        "  !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n",
        "  \n",
        "print(\"Done!\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hIvJtxwTGcb"
      },
      "source": [
        "#@title Import from URL{ form-width: \"30%\", display-mode: \"form\" }\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"unzip to content\" #@param [\"unzip to content\", \"unzip to content/workspace\", \"unzip to content/workspace/data_src\", \"unzip to content/workspace/data_src/aligned\", \"unzip to content/workspace/data_dst\", \"unzip to content/workspace/data_dst/aligned\", \"unzip to content/workspace/model\", \"download to content/workspace\"]\n",
        "\n",
        "import urllib\n",
        "from pathlib import Path\n",
        "\n",
        "def unzip(zip_path, dest_path):\n",
        "\n",
        "    \n",
        "  unzip_cmd = \" unzip -q \" + zip_path + \" -d \"+dest_path\n",
        "  !$unzip_cmd  \n",
        "  rm_cmd = \"rm \"+dest_path + url_path.name\n",
        "  !$rm_cmd\n",
        "  print(\"Unziped!\")\n",
        "  \n",
        "\n",
        "if Mode == \"unzip to content\":\n",
        "  dest_path = \"/content/\"\n",
        "elif Mode == \"unzip to content/workspace\":\n",
        "  dest_path = \"/content/workspace/\"\n",
        "elif Mode == \"unzip to content/workspace/data_src\":\n",
        "  dest_path = \"/content/workspace/data_src/\"\n",
        "elif Mode == \"unzip to content/workspace/data_src/aligned\":\n",
        "  dest_path = \"/content/workspace/data_src/aligned/\"\n",
        "elif Mode == \"unzip to content/workspace/data_dst\":\n",
        "  dest_path = \"/content/workspace/data_dst/\"\n",
        "elif Mode == \"unzip to content/workspace/data_dst/aligned\":\n",
        "  dest_path = \"/content/workspace/data_dst/aligned/\"\n",
        "elif Mode == \"unzip to content/workspace/model\":\n",
        "  dest_path = \"/content/workspace/model/\"\n",
        "elif Mode == \"download to content/workspace\":\n",
        "  dest_path = \"/content/workspace/\"\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  cmd = \"mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"\n",
        "  !$cmd\n",
        "\n",
        "url_path = Path(URL)\n",
        "urllib.request.urlretrieve ( URL, dest_path + url_path.name )\n",
        "\n",
        "if (url_path.suffix == \".zip\") and (Mode!=\"download to content/workspace\"):\n",
        "  unzip(dest_path + url_path.name, dest_path)\n",
        "\n",
        "  \n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V1sc7rxNKLO",
        "cellView": "form"
      },
      "source": [
        "#@title Export to URL\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"upload workspace\" #@param [\"upload workspace\", \"upload data_src\", \"upload data_dst\", \"upload data_src aligned\", \"upload data_dst aligned\", \"upload merged\", \"upload model\", \"upload result video\"]\n",
        "\n",
        "cmd_zip = \"zip -r -q \"\n",
        "\n",
        "def run_cmd(zip_path, curl_url):\n",
        "  cmd_zip = \"zip -r -q \"+zip_path\n",
        "  cmd_curl = \"curl --silent -F \"+curl_url+\" -D out.txt > /dev/null\"\n",
        "  !$cmd_zip\n",
        "  !$cmd_curl\n",
        "\n",
        "\n",
        "if Mode == \"upload workspace\":\n",
        "  %cd \"/content\"\n",
        "  run_cmd(\"workspace.zip workspace/\",\"'data=@/content/workspace.zip' \"+URL)\n",
        "elif Mode == \"upload data_src\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src.zip data_src/\", \"'data=@/content/workspace/data_src.zip' \"+URL)\n",
        "elif Mode == \"upload data_dst\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst.zip data_dst/\", \"'data=@/content/workspace/data_dst.zip' \"+URL)\n",
        "elif Mode == \"upload data_src aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src_aligned.zip data_src/aligned\", \"'data=@/content/workspace/data_src_aligned.zip' \"+URL )\n",
        "elif Mode == \"upload data_dst aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst_aligned.zip data_dst/aligned/\", \"'data=@/content/workspace/data_dst_aligned.zip' \"+URL)\n",
        "elif Mode == \"upload merged\":\n",
        "  %cd \"/content/workspace/data_dst\"\n",
        "  run_cmd(\"merged.zip merged/\",\"'data=@/content/workspace/data_dst/merged.zip' \"+URL )\n",
        "elif Mode == \"upload model\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"model.zip model/\", \"'data=@/content/workspace/model.zip' \"+URL)\n",
        "elif Mode == \"upload result video\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"result.zip result.mp4\", \"'data=@/content/workspace/result.zip' \"+URL)\n",
        "  \n",
        "  \n",
        "!rm *.zip\n",
        "\n",
        "%cd \"/content\"\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta6ue_UGMkki",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9cc428-e92a-4f80-93eb-55ada5c78c93"
      },
      "source": [
        "#@title Delete and recreate\n",
        "Mode = \"Delete and recreate workspace\" #@param [\"Delete and recreate workspace\", \"Delete models\", \"Delete data_src\", \"Delete data_src aligned\", \"Delete data_src video\", \"Delete data_dst\", \"Delete data_dst aligned\", \"Delete merged frames\"]\n",
        "\n",
        "%cd \"/content\" \n",
        "\n",
        "if Mode == \"Delete and recreate workspace\":\n",
        "  cmd = \"rm -r /content/workspace ; mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"  \n",
        "elif Mode == \"Delete models\":\n",
        "  cmd = \"rm -r /content/workspace/model/*\"\n",
        "elif Mode == \"Delete data_src\":\n",
        "  cmd = \"rm /content/workspace/data_src/*.png || rm -r /content/workspace/data_src/*.jpg\"\n",
        "elif Mode == \"Delete data_src aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_src/aligned/*\"\n",
        "elif Mode == \"Delete data_src video\":\n",
        "  cmd = \"rm -r /content/workspace/data_src.*\"\n",
        "elif Mode == \"Delete data_dst\":\n",
        "  cmd = \"rm /content/workspace/data_dst/*.png || rm /content/workspace/data_dst/*.jpg\"\n",
        "elif Mode == \"Delete data_dst aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/aligned/*\"\n",
        "elif Mode == \"Delete merged frames\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/merged; rm -r /content/workspace/data_dst/merged_mask\"\n",
        "  \n",
        "!$cmd\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUNVcbujhm00"
      },
      "source": [
        "## Extract, sorting and faceset tools\n",
        "* Extract frames for SRC or DST video.\n",
        "* Denoise SRC or DST video. \"Factor\" param set intesity of denoising\n",
        "* Detect and align faces. If you need, you can get frames with debug landmarks.\n",
        "* Export workspace to Google Drive after extract and sort it manually (In \"Manage Workspace\" block)\n",
        "* You can enhance your facesets with DFL FacesetEnhancer.\n",
        "* Apply or remove trained XSeg model to the extracted faces\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwJEbz5Nhot0",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41c1020-6095-457f-8800-036d659eae2f"
      },
      "source": [
        "#@title Extract frames\n",
        "Video = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed extract-video\"\n",
        "\n",
        "if Video == \"data_dst\":\n",
        "  cmd+= \" --input-file workspace/data_dst.* --output-dir workspace/data_dst/\"\n",
        "else:\n",
        "  cmd+= \" --input-file workspace/data_src.* --output-dir workspace/data_src/\"\n",
        "  \n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "[0] Enter FPS ( ?:help ) : 0\n",
            "0\n",
            "[png] Output image format ( png/jpg ?:help ) : png\n",
            "png\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/workspace/data_src.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "  Duration: 00:00:42.49, start: 119.512993, bitrate: 416 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p(tv, bt709), 640x360 [SAR 1:1 DAR 16:9], 315 kb/s, 25 fps, 25 tbr, 12800 tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 96 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/workspace/data_src/%5d.png':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: png, rgb24, 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame= 1062 fps= 69 q=-0.0 Lsize=N/A time=00:00:42.48 bitrate=N/A speed=2.77x    \n",
            "video:270127kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFmPo0s2lTil",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd0d291-9b0c-468c-dc74-904d833d2938"
      },
      "source": [
        "#@title Denoise frames\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Factor = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed denoise-image-sequence --input-dir workspace/\"+Data+\" --factor \"+str(Factor)\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "[7] Denoise factor? ( 1-20 ) : 7\n",
            "7\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '/content/workspace/data_src/%6d.png':\n",
            "  Duration: 00:00:42.48, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 640x360 [SAR 1:1 DAR 16:9], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 (png) -> hqdn3d\n",
            "  hqdn3d -> Stream #0:0 (png)\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/workspace/data_src/%6d.png':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: png, rgb24, 640x360 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame= 1062 fps= 52 q=-0.0 Lsize=N/A time=00:00:42.48 bitrate=N/A speed=2.09x    \n",
            "video:255678kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmq0Sj2bmq7d",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a2e320-aef8-4546-a41a-45373591385c"
      },
      "source": [
        "#@title Detect faces\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Detector = \"S3FD\" #@param [\"S3FD\", \"S3FD (whole face)\"]\n",
        "Debug = False #@param {type:\"boolean\"}\n",
        "\n",
        "detect_type = \"s3fd\"\n",
        "dbg = \" --output-debug\" if Debug else \" --no-output-debug\"\n",
        "\n",
        "folder = \"workspace/\"+Data\n",
        "folder_aligned = folder+\"/aligned\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py extract --input-dir \"+folder+\" --output-dir \"+folder_aligned\n",
        "cmd+=\" --detector \"+detect_type+\" --force-gpu-idxs 0\"+dbg\n",
        "\n",
        "if \"whole face\" in Detector:\n",
        "  cmd+=\" --face-type whole_face\" \n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "[wf] Face type ( f/wf/head ?:help ) : wf\n",
            "wf\n",
            "[0] Max number of faces from image ( ?:help ) : 0\n",
            "0\n",
            "[512] Image size ( 256-2048 ?:help ) : 512\n",
            "512\n",
            "[90] Jpeg quality ( 1-100 ?:help ) : 90\n",
            "90\n",
            "Extracting faces...\n",
            "Running on Tesla T4\n",
            "100% 1062/1062 [04:40<00:00,  3.79it/s]\n",
            "-------------------------\n",
            "Images found:        1062\n",
            "Faces detected:      1062\n",
            "-------------------------\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRNxUFE6p6Eu",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26910182-1f73-4960-f492-b40418596082"
      },
      "source": [
        "#@title Sort aligned\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "sort_type = \"hist\" #@param [\"blur\", \"face-yaw\", \"face-pitch\", \"face-source-rect-size\", \"hist\", \"hist-dissim\", \"brightness\", \"hue\", \"black\", \"origname\", \"oneface\", \"final\", \"final-faster\", \"absdiff\"]\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py sort --input-dir workspace/\"+Data+\"/aligned --by \"+sort_type\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Running sort tool.\n",
            "\n",
            "Sorting by histogram similarity...\n",
            "Running on 1 threads\n",
            "Sorting: 100% 1062/1062 [00:04<00:00, 232.75it/s]\n",
            "Renaming: 100% 1062/1062 [00:00<00:00, 28264.54it/s]\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5MbnVDyXkP7",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08a10f7e-7ad2-4df3-9c4d-866200864e15"
      },
      "source": [
        "#@title Faceset Enhancer\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "data_path = \"/content/workspace/\"+Data+\"/aligned\"\n",
        "cmd = \"/content/DeepFaceLab/main.py facesettool enhance --input-dir \"+data_path\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Choose one or several GPU idxs (separated by comma).\n",
            "\n",
            "[CPU] : CPU\n",
            "  [0] : Tesla T4\n",
            "\n",
            "[0] Which GPU indexes to choose? : 0\n",
            "0\n",
            "\n",
            "Enhancing faceset in data_src/aligned\n",
            "Processing to data_src/aligned_enhanced\n",
            "Running on Tesla T4.\n",
            "100% 1062/1062 [34:42<00:00,  1.96s/it]\n",
            "[y] \n",
            "Merge data_src/aligned_enhanced to data_src/aligned ? ( y/n ) : y\n",
            "Copying processed files to data_src/aligned\n",
            "Removing data_src/aligned_enhanced\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VVvtoBMGnrA",
        "cellView": "form"
      },
      "source": [
        "#@title Apply or remove XSeg mask to the faces\n",
        "Mode = \"Remove mask\" #@param [\"Apply mask\", \"Remove mask\"]\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "main_path = \"/content/DeepFaceLab/main.py \"\n",
        "data_path = \"/content/workspace/\"+Data+\"/aligned \"\n",
        "mode_arg = \"apply \" if Mode == \"Apply mask\" else \"remove \"\n",
        "cmd = main_path+\"xseg \"+mode_arg+\"--input-dir \"+data_path\n",
        "cmd += \"--model-dir /content/workspace/model\" if mode_arg == \"apply \" else \"\"\n",
        "\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSyIzrLArRzM"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTuyUxgdLA13"
      },
      "source": [
        "## Train model\n",
        "\n",
        "* Choose your model type, but SAEHD is recommend for everyone\n",
        "* Set model options on output field\n",
        "* You can see preview manually, if go to model folder in filemanager and double click on preview.jpg file\n",
        "* Your workspace will be archived and upload to mounted Drive after 11 hours from start session\n",
        "* If you select \"Backup_every_hour\" option, your workspace will be backed up every hour.\n",
        "* Also, you can export your workspace manually in \"Manage workspace\" block\n",
        "* \"Silent_Start\" option provides to automatically start with best GPU and last used model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Kya-PJLDhv",
        "cellView": "form"
      },
      "source": [
        "#@title Training\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"Quick96\", \"XSeg\"]\n",
        "Backup_every_hour = True #@param {type:\"boolean\"}\n",
        "Silent_Start = True #@param {type:\"boolean\"}\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import psutil, os, time\n",
        "\n",
        "p = psutil.Process(os.getpid())\n",
        "uptime = time.time() - p.create_time()\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  if not os.path.exists('workspace.zip'):\n",
        "    print(\"Creating workspace archive ...\")\n",
        "    !zip -r -q workspace.zip workspace\n",
        "    print(\"Archive created!\")\n",
        "  else:\n",
        "    print(\"Archive exist!\")\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  print(\"Time to end session: \"+str(round((43200-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(3600)\n",
        "  backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -r -q workspace.zip workspace/model'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "elif (round(39600-uptime) > 0):\n",
        "  print(\"Time to backup: \"+str(round((39600-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(round(39600-uptime))\n",
        "  backup_cmd = \" --execute-program \"+backup_time+\" \\\"import os; os.system('zip -r -q workspace.zip workspace'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "else:\n",
        "  print(\"Session expires in less than an hour.\")\n",
        "  backup_cmd = \"\"\n",
        "    \n",
        "cmd = \"DeepFaceLab/main.py train --training-data-src-dir workspace/data_src/aligned --training-data-dst-dir workspace/data_dst/aligned --pretraining-data-dir pretrain --model-dir workspace/model --model \"+Model\n",
        "\n",
        "if Model == \"Quick96\":\n",
        "  cmd+= \" --pretrained-model-dir pretrain_Q96\"\n",
        "\n",
        "if Silent_Start:\n",
        "  cmd+= \" --silent-start\"\n",
        "\n",
        "if (backup_cmd != \"\"):\n",
        "  train_cmd = (cmd+backup_cmd)\n",
        "else:\n",
        "  train_cmd = (cmd)\n",
        "\n",
        "!python $train_cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avAcSL_uvtq_"
      },
      "source": [
        "## Merge frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Y8K22Sv9Gn",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2796700-f451-4e25-80dd-d9d60b361677"
      },
      "source": [
        "#@title Merge\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"Quick96\" ]\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py merge --input-dir workspace/data_dst --output-dir workspace/data_dst/merged --output-mask-dir workspace/data_dst/merged_mask --aligned-dir workspace/data_dst/aligned --model-dir workspace/model --model \"+Model\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Running merger.\n",
            "\n",
            "Choose one of saved models, or enter a name to create a new model.\n",
            "[r] : rename\n",
            "[d] : delete\n",
            "\n",
            "[0] : model - latest\n",
            " : 0\n",
            "0\n",
            "Loading model_SAEHD model...\n",
            "Initializing models: 100% 4/4 [00:01<00:00,  3.05it/s]\n",
            "============ Model Summary =============\n",
            "==                                    ==\n",
            "==            Model name: model_SAEHD ==\n",
            "==                                    ==\n",
            "==     Current iteration: 7155        ==\n",
            "==                                    ==\n",
            "==---------- Model Options -----------==\n",
            "==                                    ==\n",
            "==            resolution: 128         ==\n",
            "==             face_type: f           ==\n",
            "==     models_opt_on_gpu: True        ==\n",
            "==                 archi: liae-ud     ==\n",
            "==               ae_dims: 256         ==\n",
            "==                e_dims: 64          ==\n",
            "==                d_dims: 64          ==\n",
            "==           d_mask_dims: 22          ==\n",
            "==       masked_training: True        ==\n",
            "==       eyes_mouth_prio: False       ==\n",
            "==           uniform_yaw: False       ==\n",
            "==             adabelief: True        ==\n",
            "==            lr_dropout: n           ==\n",
            "==           random_warp: True        ==\n",
            "==       true_face_power: 0.0         ==\n",
            "==      face_style_power: 0.0         ==\n",
            "==        bg_style_power: 0.0         ==\n",
            "==               ct_mode: none        ==\n",
            "==              clipgrad: False       ==\n",
            "==              pretrain: False       ==\n",
            "==       autobackup_hour: 1           ==\n",
            "== write_preview_history: False       ==\n",
            "==           target_iter: 0           ==\n",
            "==       random_src_flip: False       ==\n",
            "==       random_dst_flip: True        ==\n",
            "==            batch_size: 8           ==\n",
            "==             gan_power: 0.0         ==\n",
            "==        gan_patch_size: 16          ==\n",
            "==              gan_dims: 16          ==\n",
            "==                                    ==\n",
            "==------------ Running On ------------==\n",
            "==                                    ==\n",
            "==          Using device: CPU         ==\n",
            "==                                    ==\n",
            "========================================\n",
            "Choose mode: \n",
            "(0) original\n",
            "(1) overlay\n",
            "(2) hist-match\n",
            "(3) seamless\n",
            "(4) seamless-hist-match\n",
            "(5) raw-rgb\n",
            "(6) raw-predict\n",
            "\n",
            "[1] : 1\n",
            "1\n",
            "Choose mask mode: \n",
            "(1) dst\n",
            "(2) learned-prd\n",
            "(3) learned-dst\n",
            "(4) learned-prd*learned-dst\n",
            "(5) learned-prd+learned-dst\n",
            "(6) XSeg-prd\n",
            "(7) XSeg-dst\n",
            "(8) XSeg-prd*XSeg-dst\n",
            "(9) learned-prd*learned-dst*XSeg-prd*XSeg-dst\n",
            "\n",
            "[1] : \n",
            "1\n",
            "[0] Choose erode mask modifier ( -400..400 ) : \n",
            "0\n",
            "[0] Choose blur mask modifier ( 0..400 ) : \n",
            "0\n",
            "[0] Choose motion blur power ( 0..100 ) : \n",
            "0\n",
            "[0] Choose output face scale modifier ( -50..50 ) : \n",
            "0\n",
            "Color transfer to predicted face ( rct/lct/mkl/mkl-m/idt/idt-m/sot-m/mix-m ) : \n",
            "\n",
            "Choose sharpen mode: \n",
            "(0) None\n",
            "(1) box\n",
            "(2) gaussian\n",
            "\n",
            "[0] ( ?:help ) : 2\n",
            "2\n",
            "[0] Choose blur/sharpen amount ( -100..100 ) : \n",
            "0\n",
            "[0] Choose super resolution power ( 0..100 ?:help ) : 20\n",
            "20\n",
            "[0] Choose image degrade by denoise power ( 0..500 ) : \n",
            "0\n",
            "[0] Choose image degrade by bicubic rescale power ( 0..100 ) : \n",
            "0\n",
            "[0] Degrade color power of final image ( 0..100 ) : \n",
            "0\n",
            "\n",
            "[8] Number of workers? ( 1-2 ?:help ) : \n",
            "8\n",
            "Collecting alignments:   0% 0/1109 [00:00<?, ?it/s]\n",
            "\n",
            "/!\\ 00000.jpg is not a dfl image file\n",
            "Collecting alignments: 100% 1109/1109 [00:17<00:00, 65.12it/s]\n",
            "Computing motion vectors: 100% 1109/1109 [00:01<00:00, 956.45it/s]\n",
            "Running on CPU0.\n",
            "Running on CPU1.\n",
            "Running on CPU2.\n",
            "Running on CPU3.\n",
            "Running on CPU4.\n",
            "Running on CPU6.\n",
            "Running on CPU5.\n",
            "Running on CPU7.\n",
            "Merging:   0% 0/1109 [00:00<?, ?it/s]\n",
            "\n",
            "no faces found for 00001.png, copying without faces\n",
            "Merging: 100% 1109/1109 [1:09:26<00:00,  3.76s/it]\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNeGfiZpxlnz",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a152f98-dd7a-4292-a802-5cd10cbd44dc"
      },
      "source": [
        "#@title Get result video \n",
        "Mode = \"result video\" #@param [\"result video\", \"result_mask video\"]\n",
        "Copy_to_Drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Mode == \"result video\":\n",
        "  !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged --output-file workspace/result.mp4 --reference-file workspace/data_dst.mp4 --include-audio\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged_mask --output-file workspace/result_mask.mp4 --reference-file workspace/data_dst.mp4\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[16] Bitrate of output file in MB/s : \n",
            "16\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2pipe, from 'pipe:':\n",
            "  Duration: N/A, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 640x360, 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Input #1, mov,mp4,m4a,3gp,3g2,mj2, from '/content/workspace/data_dst.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41avc1\n",
            "    creation_time   : 2021-02-02T17:50:45.000000Z\n",
            "    playback_requirements: QuickTime 6.0 or greater\n",
            "    playback_requirements-eng: QuickTime 6.0 or greater\n",
            "    encoder         : vlc 3.0.8 stream output\n",
            "    encoder-eng     : vlc 3.0.8 stream output\n",
            "  Duration: 00:00:44.36, start: 0.000000, bitrate: 371 kb/s\n",
            "    Stream #1:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 95 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:50:45.000000Z\n",
            "      handler_name    : SoundHandler\n",
            "    Stream #1:1(eng): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p, 640x360 [SAR 1:1 DAR 16:9], 270 kb/s, 25 fps, 25 tbr, 90k tbn, 50 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:50:45.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
            "  Stream #1:0 -> #0:1 (aac (native) -> aac (native))\n",
            "\u001b[0;35m[image2pipe @ 0x5609acea4000] \u001b[0m\u001b[0;33mThread message queue blocking; consider raising the thread_queue_size option (current value: 8)\n",
            "\u001b[0m\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mprofile High, level 4.1\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=abr mbtree=1 bitrate=16000 ratetol=1.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '/content/workspace/result.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuv420p(progressive), 640x360, q=-1--1, 16000 kb/s, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 libx264\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/16000000 buffer size: 0 vbv_delay: -1\n",
            "    Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 192 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2021-02-02T17:50:45.000000Z\n",
            "      handler_name    : SoundHandler\n",
            "      encoder         : Lavc57.107.100 aac\n",
            "frame= 1109 fps= 57 q=-1.0 Lsize=   17882kB time=00:00:44.32 bitrate=3304.5kbits/s speed=2.27x    \n",
            "video:16809kB audio:1039kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.184317%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mframe I:5     Avg QP: 0.08  size: 82241\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mframe P:490   Avg QP: 0.03  size: 22773\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mframe B:614   Avg QP: 1.67  size:  9189\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mconsecutive B-frames: 20.7% 12.8% 10.6% 55.9%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mmb I  I16..4: 38.0% 14.4% 47.6%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mmb P  I16..4:  1.4%  0.5%  0.5%  P16..4: 35.0%  6.8%  7.6%  0.0%  0.0%    skip:48.3%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mmb B  I16..4:  0.0%  0.0%  0.1%  B16..8: 24.7%  5.6%  4.2%  direct: 7.8%  skip:57.6%  L0:40.5% L1:52.1% BI: 7.4%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mfinal ratefactor: -19.47\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0m8x8 transform intra:18.8% inter:27.6%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mcoded y,uvDC,uvAC intra: 52.3% 71.4% 69.7% inter: 23.3% 29.3% 29.3%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mi16 v,h,dc,p: 66% 23%  9%  3%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 27% 18% 35%  2%  4%  5%  4%  3%  3%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 32% 21% 12%  5%  7%  7%  6%  6%  5%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mi8c dc,h,v,p: 50% 24% 22%  5%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mref P L0: 91.6%  3.1%  3.9%  1.4%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mref B L0: 96.3%  3.1%  0.6%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mref B L1: 99.4%  0.6%\n",
            "\u001b[1;36m[libx264 @ 0x5609acf12000] \u001b[0mkb/s:3104.10\n",
            "\u001b[1;36m[aac @ 0x5609acf12f00] \u001b[0mQavg: 1210.445\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}